{"posts":[{"title":"Rethinking Memory in LLM based Agents - Representations, Operations, and Emerging Topics","text":"原文地址 一、论文核心内容解析这篇论文聚焦于大语言模型（LLM）驱动智能体中的记忆机制，从记忆的表示形式、操作方法及未来研究方向等方面进行了系统性的论述，试图为LLM智能体的记忆研究提供一个全面的理论框架和实践指导。 1. 论文提出的主要问题当前关于LLM智能体记忆的研究主要集中在具体的应用层面（如个性化对话、知识增强生成等），而忽视了记忆动态操作的基础性问题。现有研究存在以下不足： 缺乏对记忆操作（如更新、遗忘、索引等）的系统性分析。 过于关注单一子领域（如长上下文建模、个性化、知识编辑），缺乏统一的框架将这些研究串联起来。 缺乏标准化的评估基准和工具，难以量化记忆相关技术的效果。 2. 论文的贡献 记忆的分类与定义 参数记忆（Parametric Memory）：隐式存储于模型参数中，主要通过模型权重表示知识，具备快速检索能力，但更新困难且不透明。 上下文记忆（Contextual Memory）：显式存储外部信息，分为非结构化（如文本、图像、视频等）和结构化（如知识图谱、表格等）两类，适合动态更新和检索。 时间维度：记忆按时间跨度划分为短期记忆（如对话历史、KV缓存）和长期记忆（如知识库、用户偏好）。 功能类型：借鉴认知心理学，将记忆功能分为情景记忆、语义记忆、程序记忆和工作记忆，分别对应对话历史、知识推理、任务执行模式和实时决策支持。 记忆操作的六大核心机制 整合（Consolidation）：将短期记忆转化为长期记忆，支持知识持久化和个性化。 索引（Indexing）：构建辅助索引以便高效检索，支持符号化和神经网络检索。 更新（Updating）：动态修改记忆内容以融入新知识或纠正错误内容。 遗忘（Forgetting）：选择性移除过时或无用的信息，提升记忆效率，减少干扰。 检索（Retrieval）：根据输入高效定位和访问存储的相关记忆片段。 压缩（Condensation）：在有限的上下文窗口中，通过保留关键信息并去除冗余内容实现高效使用。 四大关键研究主题 长期记忆（Long-Term Memory）：探索多轮对话、知识增强生成（RAG）和个性化等场景中的记忆管理与应用。 长上下文记忆（Long-Context Memory）：解决超长上下文处理中的计算效率、上下文压缩和“中间丢失”问题。 参数记忆修改（Parametric Memory Modification）：研究模型编辑、知识遗忘和持续学习，提升模型内部知识的动态适应性。 多源记忆（Multi-Source Memory）：研究如何整合异构数据源（如文本、表格、多模态输入），支持复杂推理和冲突解决。 评估基准与工具 提出了多种记忆相关的评估数据集和指标（如MemoryBank、LongMemEval、TOFU等），涵盖记忆的更新、遗忘、检索、压缩等操作。 提供了开发工具和框架，如LangChain、LlamaIndex、MemOS等，用于支持记忆的存储、更新和检索。 归纳了记忆相关产品（如ChatGPT、Replika、GitHub Copilot）的特点及其在记忆管理上的实现方式。 未来研究方向 统一评估框架：开发标准化的评估基准，涵盖记忆的动态操作（如整合、更新、遗忘）和多会话场景。 长上下文处理：在计算效率与上下文表达能力之间取得平衡，探索基于强化学习的上下文管理机制。 多源记忆整合：解决异构数据来源整合中的冲突与一致性问题，优化索引和压缩方法。 生物启发的记忆设计：借鉴人类记忆的动态重整、分层结构和稳定性-可塑性平衡机制，设计更高效的AI记忆系统。 二、复盘与思考 全面且系统的记忆框架论文通过对记忆类型、操作和功能的划分，为LLM智能体的记忆研究提供了清晰的理论框架。这种系统化的视角有助于研究者从整体上理解记忆在不同场景中的作用，并推动记忆技术在实际应用中的落地。 记忆操作的关键性论文将记忆操作（如整合、更新、遗忘等）作为核心研究内容，强调其对智能体动态适应性的决定性作用。这一视角非常重要，因为记忆的动态操作能力直接关系到智能体的长期学习和实时推理能力。 现实应用的需求与挑战论文通过分析现有产品（如ChatGPT、Replika、GitHub Copilot等）的记忆机制，揭示了当前记忆技术在实际应用中的不足： 个性化与隐私保护的平衡：如何实现用户数据的个性化存储与高效利用，同时保障数据隐私？ 多模态与多源数据整合：如何高效整合文本、图像、音频等多模态信息，并解决异构数据源间的冲突？ 长上下文处理：如何在不增加计算成本的情况下高效处理超长上下文数据？ 未来研究方向的启发 生物启发的记忆机制：人类记忆的动态演化、分层结构和自我模型构建能力为AI记忆研究提供了重要的灵感。未来的研究可以进一步探索如何模拟人类记忆的重整、压缩和长期演化机制。 统一评估框架的构建：目前记忆相关研究的评估分散且缺乏规范，未来需要开发能够覆盖多种记忆操作和场景的统一评估框架，以推动领域的标准化发展。 多源记忆冲突的解决：多源记忆整合中的异构性和冲突问题是当前研究的难点，设计鲁棒的冲突解决策略和一致性校准机制将是重要突破方向。 三、总结这篇论文通过全面的记忆分类、操作框架和研究主题分析，为LLM智能体的记忆研究提供了新的视角和方向。其提出的六大记忆操作和四大研究主题，不仅对学术界具有重要的理论意义，也为工业界的实际应用提供了清晰的指导。然而，记忆技术仍处于早期阶段，未来需要在统一评估、多模态整合、生物启发设计等方向上持续深入探索，以实现更加智能和适应性更强的AI系统。","link":"/2026/02/25/Rethinking-Memory-in-LLM-based-Agents/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2026/02/20/hello-world/"},{"title":"Langchain 构建SQL Agent中遇到的坑","text":"1.什么是langchainLangChain 是一个开源的软件开发框架，旨在简化由大型语言模型（LLM）（如 GPT-4、Claude、Llama 等）驱动的应用程序的开发过程。简单来说，如果把大语言模型比作一个“大脑”，那么 LangChain 就是给这个大脑装上了“四肢”（工具）、“耳朵”（数据输入）和“记事本”（记忆），让它能够真正地去执行复杂的任务，而不仅仅是陪你聊天。 2.如何利用langchain来快速构建自己的sql-agent2.1 安装必要的库需要安装 LangChain 的核心库、OpenAI 接口库（推荐使用 OpenAI，效果最好）以及社区工具包 1uv add langchain langchain-community langchain-openai langgraph 2.2 核心代码实现为了能直接运行，下面的代码包含了一个临时创建的 SQLite 内存数据库。在实际生产中，你只需要把数据库连接字符串换成你的 MySQL 或 PostgreSQL 地址即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import osfrom sqlalchemy import create_engine, Column, Integer, String, MetaData, Table, insert# 1. 导入 LangChain 相关模块from langchain_community.utilities import SQLDatabasefrom langchain_community.agent_toolkits import create_sql_agentfrom langchain_openai import ChatOpenAI# ==========================================# 准备工作：设置 API Key (请替换为你自己的 Key)# ==========================================os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;sk-...&quot; # ==========================================# A. 创建一个模拟数据库 (仅用于演示，实际项目中不需要这一步)# ==========================================# 创建内存数据库engine = create_engine(&quot;sqlite:///:memory:&quot;)metadata = MetaData()# 创建一个 'users' 表users = Table( &quot;users&quot;, metadata, Column(&quot;id&quot;, Integer, primary_key=True), Column(&quot;name&quot;, String), Column(&quot;age&quot;, Integer), Column(&quot;city&quot;, String),)metadata.create_all(engine)# 插入一些测试数据with engine.connect() as conn: conn.execute(insert(users), [ {&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 25, &quot;city&quot;: &quot;New York&quot;}, {&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 30, &quot;city&quot;: &quot;San Francisco&quot;}, {&quot;name&quot;: &quot;Charlie&quot;, &quot;age&quot;: 35, &quot;city&quot;: &quot;New York&quot;}, {&quot;name&quot;: &quot;David&quot;, &quot;age&quot;: 40, &quot;city&quot;: &quot;London&quot;}, ]) conn.commit()# ==========================================# B. 连接数据库# ==========================================# 在实际项目中，URI 可能是 &quot;postgresql://user:pass@localhost:5432/mydb&quot;db = SQLDatabase(engine=engine)# ==========================================# C. 初始化 LLM (大模型)# ==========================================# 建议使用 gpt-4 或 gpt-3.5-turbo，温度设为 0 以保证 SQL 生成的准确性llm = ChatOpenAI(model=&quot;gpt-3.5-turbo&quot;, temperature=0)# ==========================================# D. 创建 SQL Agent# ==========================================# agent_type=&quot;openai-tools&quot; 是目前最高效的模式agent_executor = create_sql_agent( llm=llm, db=db, agent_type=&quot;openai-tools&quot;, verbose=True # 开启后可以看到 Agent 的思考过程 (生成的 SQL 等))# ==========================================# E. 运行查询# ==========================================query = &quot;来自 New York 的用户平均年龄是多少？&quot;print(f&quot;用户提问: {query}&quot;)response = agent_executor.invoke({&quot;input&quot;: query})print(f&quot;\\n最终回答: {response['output']}&quot;) 3.内置方法的弊端虽然 create_sql_agent 和 SQLDatabase 等内置方法非常适合快速构建原型（Demo），但在生产环境中直接使用它们，通常会遇到很多严重的瓶颈和风险。 以下是 LangChain 内置 SQL Agent 方法的主要弊端： 3.1 Token 消耗与上下文限制这是最常见的问题。内置方法通常会将数据库的 表结构（Schema） 直接放入Prompt中发送给LLM。 弊端：如果你的数据库有 100 张表，或者表中有几百个字段，Prompt 会瞬间变得非常长，甚至超过 LLM 的上下文窗口限制（Context Limit）。 这就会造成 每次查询都要发送几千个 Token 的表结构，API 费用极高（自己部署）。 LLM 面对过多的无关表信息，注意力会被分散，导致推理能力下降，选错表或字段 3.2 缺乏领域知识LLM 懂 SQL 语法，但它不懂业务逻辑。 弊端：数据库字段名往往是缩写或晦涩的（如 t_stat_01, is_del）。内置 Agent 只能根据字段名“猜”意思。 这就会造成生成的 SQL 语法正确，但业务结果是错的。 3.3 幻觉与错误 弊端：LLM 可能会臆造不存在的列名，或者混淆相似的列名 后果：虽然内置 Agent 有“自动纠错机制”（执行报错 -&gt; 把错误发回 LLM -&gt; LLM 重写 SQL），但这会增加延迟和 Token 消耗，而且不一定能修好。 4.如何解决4.1 RAG for Schema把表名和列的描述存入向量数据库。当用户提问时，先检索出最相关的 3-5 张表，只把这几张表的结构发给 LLM 4.2 构建自己的database tools原有SQLDatabaseToolkit一次性会获取完整的表格数据，但是实际需要的字段数据不多，因此会造成过多无关字段、敏感数据或消耗大量Token，因此可以构建自己Database tools，工具主要针对以下进行优化 白名单/黑名单机制：只向 LLM 暴露特定的表和字段。 简化 Schema 格式：不发送完整的 CREATE TABLE 语句，只发送简单的 列名: 类型 描述。 禁止获取样本数据：内置工具通常会查询前 3 行数据作为样本，自定义工具可以完全禁止这一行为。 123456789101112131415161718192021222324252627@tooldef get_safe_table_schema(table_name: str): &quot;&quot;&quot; 获取指定表的结构信息。 只返回允许访问的字段，不包含敏感字段或样本数据。 &quot;&quot;&quot; if table_name not in VISIBLE_SCHEMA: return f&quot;Error: Table '{table_name}' does not exist or access is denied.&quot; # 使用 SQLAlchemy Inspector 获取真实的列信息 inspector = inspect(engine) columns = inspector.get_columns(table_name) # 过滤字段 allowed_columns = VISIBLE_SCHEMA[table_name] safe_columns_info = [] for col in columns: if col['name'] in allowed_columns: # 拼接成简化的格式: &quot;name (VARCHAR)&quot; col_str = f&quot;{col['name']} ({col['type']})&quot; safe_columns_info.append(col_str) # 构造返回给 LLM 的文本 schema_text = f&quot;Table: {table_name}\\nColumns:\\n&quot; + &quot;\\n&quot;.join(f&quot;- {c}&quot; for c in safe_columns_info) return schema_text 总结LangChain 的 create_sql_agent 就像一把瑞士军刀，能让我们在 5 分钟内快速验证“Text-to-SQL”的可行性。然而，当我们试图将其推向生产环境时，“开箱即用”的便利性往往伴随着不可控的风险。 从 Demo 到 Production 的跨越，本质上是一场关于 Context（上下文）与Control（控制权） 的博弈： 拒绝暴力填充：不再将整个数据库 Schema 一股脑塞给 LLM，而是通过 RAG（检索增强生成） 按需加载相关表，解决 Token 爆炸和注意力分散问题。精细化权限管理：放弃粗粒度的内置工具，转而构建自定义 Database Tools。通过白名单机制和 Schema 简化，既保护了敏感数据（如密码、薪资），又大幅降低了 API 成本。 注入业务语义：LLM 懂 SQL 语法但不懂业务逻辑。通过自定义工具层，我们可以将复杂的业务规则（如“毛利计算方式”）封装在工具内部，而不是依赖模型去“猜”。一句话概括：在构建企业级 SQL Agent 时，不要迷信 LangChain 的“魔法”，只有通过自定义工具将数据库的解释权和访问权牢牢掌握在自己手中，才能构建出既安全又精准的智能应用。","link":"/2026/02/26/how-to-build-valid-sql-tool-in-agent/"}],"tags":[{"name":"Agent","slug":"Agent","link":"/tags/Agent/"},{"name":"Memory","slug":"Memory","link":"/tags/Memory/"},{"name":"Langchain","slug":"Langchain","link":"/tags/Langchain/"},{"name":"SQL-Agent","slug":"SQL-Agent","link":"/tags/SQL-Agent/"}],"categories":[{"name":"论文复盘","slug":"论文复盘","link":"/categories/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%9B%98/"},{"name":"工程复盘","slug":"工程复盘","link":"/categories/%E5%B7%A5%E7%A8%8B%E5%A4%8D%E7%9B%98/"}],"pages":[]}